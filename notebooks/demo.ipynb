{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yezhengkai/LawGPT/blob/main/notebooks/demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount google drive and move in project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move in the project directory\n",
    "%mkdir -p /content/drive/MyDrive/side-project/LawGPT\n",
    "%cd /content/drive/MyDrive/side-project/LawGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up poetry to manage dependencies in virtual env and instantiate project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref:\n",
    "# - https://stackoverflow.com/questions/75245758/how-to-use-poetry-in-google-colab\n",
    "# - https://github.com/elise-chin/poetry-and-colab/blob/main/Using_python_poetry_in_Google_Colab.ipynb\n",
    "!pip install -qqq --progress-bar off poetry # install poetry\n",
    "!poetry install --no-ansi --without dev --extras \"app\"  # instantiate project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add venv to the first position of the search path\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def get_env_path() -> str:\n",
    "    subproc_out = subprocess.run(\n",
    "        'poetry env info -p',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    if subproc_out.returncode != 0:\n",
    "        raise RuntimeError('Unable to get env path')\n",
    "    return subproc_out.stdout\n",
    "\n",
    "PY_VERSION = re.search(r\"(?<=py)\\d\\.\\d+\", get_env_path().strip()).group(0)\n",
    "VENV_PATH = f\"{get_env_path().strip()}/lib/python{PY_VERSION}/site-packages\"\n",
    "sys.path.insert(0, VENV_PATH)\n",
    "sys.path.insert(0, \"/content/drive/MyDrive/side-project/LawGPT/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune using lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run lawgpt finetune lora \\\n",
    "  --base-model \"bigscience/bloom-3b\" \\\n",
    "  --data-path \"./data/processed/roc_law_corpus.json\" \\\n",
    "  --output-dir \"./output/lawgpt-bloom-3b-lora-sft-v1\" \\\n",
    "  --batch-size 100 \\\n",
    "  --micro-batch-size 4 \\\n",
    "  --num-epochs 3 \\\n",
    "  --learning-rate 3e-4 \\\n",
    "  --cutoff-len 256 \\\n",
    "  --val-set-size 100 \\\n",
    "  --lora-r 8 \\\n",
    "  --lora-alpha 16 \\\n",
    "  --lora-dropout 0.05 \\\n",
    "  --lora-target-modules \"query_key_value\" \\\n",
    "  --train-on-inputs \\\n",
    "  --add-eos-token \\\n",
    "  --no-group-by-length \\\n",
    "  --wandb-project \"\" \\\n",
    "  --wandb-run-name \"\" \\\n",
    "  --wandb-watch \"\" \\\n",
    "  --wandb-log-model \"\" \\\n",
    "  --resume-from-checkpoint \"./output/lawgpt-bloom-3b-lora-sft-v1\" \\\n",
    "  --prompt-template-name \"roc_law\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run lawgpt infer \\\n",
    "  --load-8bit \\\n",
    "  --base-model \"bigscience/bloom-3b\" \\\n",
    "  --lora-weights \"./output/lawgpt-bloom-3b-lora-sft-v1\" \\\n",
    "  --prompt-template \"roc_law\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run lawgpt webui \\\n",
    "  --no-load-8bit \\\n",
    "  --base-model \"bigscience/bloom-3b\" \\\n",
    "  --lora-weights \"./output/lawgpt-bloom-3b-lora-sft-v1\" \\\n",
    "  --prompt-template \"roc_law\" \\\n",
    "  --server-name \"0.0.0.0\" \\\n",
    "  --share-gradio"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
